{
  PrintWriter out;
  String rules;
  if (args.length > 0) {
    rules=args[0];
  }
 else {
    rules="edu/stanford/nlp/ling/tokensregex/demo/rules/retokenize.rules.txt";
  }
  if (args.length > 2) {
    out=new PrintWriter(args[2]);
  }
 else {
    out=new PrintWriter(System.out);
  }
  String text;
  if (args.length > 1) {
    text=IOUtils.slurpFileNoExceptions(args[1]);
  }
 else {
    text="Do we tokenize on hyphens? one-two-three-four.  How about dates? 03-16-2015.";
  }
  Properties propertiesDefaultTokenize=new Properties();
  propertiesDefaultTokenize.setProperty("annotators","tokenize,ssplit,pos,lemma,ner");
  StanfordCoreNLP pipelineDefaultRetokenize=new StanfordCoreNLP();
  out.println("Default tokenization: ");
  runPipeline(pipelineDefaultRetokenize,text,out);
  Properties properties=new Properties();
  properties.setProperty("annotators","tokenize,retokenize,ssplit,pos,lemma,ner");
  properties.setProperty("customAnnotatorClass.retokenize","edu.stanford.nlp.pipeline.TokensRegexAnnotator");
  properties.setProperty("retokenize.rules",rules);
  StanfordCoreNLP pipelineWithRetokenize=new StanfordCoreNLP(properties);
  out.println();
  out.println("Always tokenize hyphens: ");
  runPipeline(pipelineWithRetokenize,text,out);
}
