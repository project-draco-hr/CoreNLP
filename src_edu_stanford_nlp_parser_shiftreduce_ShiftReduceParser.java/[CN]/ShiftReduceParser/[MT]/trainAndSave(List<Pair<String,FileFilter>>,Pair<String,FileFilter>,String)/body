{
  List<Tree> binarizedTrees=Generics.newArrayList();
  for (  Pair<String,FileFilter> treebank : trainTreebankPath) {
    binarizedTrees.addAll(readBinarizedTreebank(treebank.first(),treebank.second()));
  }
  int nThreads=op.trainOptions.trainingThreads;
  nThreads=nThreads <= 0 ? Runtime.getRuntime().availableProcessors() : nThreads;
  MaxentTagger tagger=null;
  if (op.testOptions.preTag) {
    Timing retagTimer=new Timing();
    tagger=new MaxentTagger(op.testOptions.taggerSerializedFile);
    redoTags(binarizedTrees,tagger,nThreads);
    retagTimer.done("Retagging");
  }
  Timing transitionTimer=new Timing();
  List<List<Transition>> transitionLists=createTransitionSequences(binarizedTrees);
  for (  List<Transition> transitions : transitionLists) {
    transitionIndex.addAll(transitions);
  }
  transitionTimer.done("Converting trees into transition lists");
  System.err.println("Number of transitions: " + transitionIndex.size());
  Random random=new Random(op.trainOptions.randomSeed);
  Treebank devTreebank=null;
  if (devTreebankPath != null) {
    devTreebank=readTreebank(devTreebankPath.first(),devTreebankPath.second());
  }
  double bestScore=0.0;
  int bestIteration=0;
  PriorityQueue<ScoredObject<ShiftReduceParser>> bestModels=null;
  if (op.trainOptions().averagedModels > 0) {
    bestModels=new PriorityQueue<ScoredObject<ShiftReduceParser>>(op.trainOptions().averagedModels + 1,ScoredComparator.ASCENDING_COMPARATOR);
  }
  List<Integer> indices=Generics.newArrayList();
  for (int i=0; i < binarizedTrees.size(); ++i) {
    indices.add(i);
  }
  Oracle oracle=null;
  if (op.trainOptions().trainingMethod == ShiftReduceTrainOptions.TrainingMethod.ORACLE) {
    oracle=new Oracle(binarizedTrees,op.compoundUnaries);
  }
  List<Update> updates=Generics.newArrayList();
  MulticoreWrapper<Integer,Pair<Integer,Integer>> wrapper=null;
  if (nThreads != 1) {
    updates=Collections.synchronizedList(updates);
    wrapper=new MulticoreWrapper<Integer,Pair<Integer,Integer>>(op.trainOptions.trainingThreads,new TrainTreeProcessor(binarizedTrees,transitionLists,updates,oracle));
  }
  IntCounter<String> featureFrequencies=null;
  if (op.trainOptions().featureFrequencyCutoff > 1) {
    featureFrequencies=new IntCounter<String>();
  }
  for (int iteration=1; iteration <= op.trainOptions.trainingIterations; ++iteration) {
    Timing trainingTimer=new Timing();
    int numCorrect=0;
    int numWrong=0;
    Collections.shuffle(indices,random);
    for (int start=0; start < indices.size(); start+=op.trainOptions.batchSize) {
      int end=Math.min(start + op.trainOptions.batchSize,indices.size());
      Triple<List<Update>,Integer,Integer> result=trainBatch(indices.subList(start,end),binarizedTrees,transitionLists,updates,oracle,wrapper);
      numCorrect+=result.second;
      numWrong+=result.third;
      for (      Update update : result.first) {
        for (        String feature : update.features) {
          Weight weights=featureWeights.get(feature);
          if (weights == null) {
            weights=new Weight();
            featureWeights.put(feature,weights);
          }
          weights.updateWeight(update.goldTransition,update.delta);
          weights.updateWeight(update.predictedTransition,-update.delta);
          if (featureFrequencies != null) {
            featureFrequencies.incrementCount(feature,(update.goldTransition >= 0 && update.predictedTransition >= 0) ? 2 : 1);
          }
        }
      }
      updates.clear();
    }
    trainingTimer.done("Iteration " + iteration);
    System.err.println("While training, got " + numCorrect + " transitions correct and "+ numWrong+ " transitions wrong");
    outputStats();
    double labelF1=0.0;
    if (devTreebank != null) {
      EvaluateTreebank evaluator=new EvaluateTreebank(op,null,this,tagger);
      evaluator.testOnTreebank(devTreebank);
      labelF1=evaluator.getLBScore();
      System.err.println("Label F1 after " + iteration + " iterations: "+ labelF1);
      if (labelF1 > bestScore) {
        System.err.println("New best dev score (previous best " + bestScore + ")");
        bestScore=labelF1;
        bestIteration=iteration;
      }
 else {
        System.err.println("Failed to improve for " + (iteration - bestIteration) + " iteration(s) on previous best score of "+ bestScore);
        if (op.trainOptions.stalledIterationLimit > 0 && (iteration - bestIteration >= op.trainOptions.stalledIterationLimit)) {
          System.err.println("Failed to improve for too long, stopping training");
          break;
        }
      }
      if (bestModels != null) {
        bestModels.add(new ScoredObject<ShiftReduceParser>(this.deepCopy(),labelF1));
        if (bestModels.size() > op.trainOptions().averagedModels) {
          bestModels.poll();
        }
      }
    }
    if (op.trainOptions().saveIntermediateModels && serializedPath != null && op.trainOptions.debugOutputFrequency > 0) {
      String tempName=serializedPath.substring(0,serializedPath.length() - 7) + "-" + FILENAME.format(iteration)+ "-"+ NF.format(labelF1)+ ".ser.gz";
      saveModel(tempName);
    }
  }
  if (wrapper != null) {
    wrapper.join();
  }
  if (bestModels != null) {
    if (op.trainOptions().cvAveragedModels && devTreebank != null) {
      List<ScoredObject<ShiftReduceParser>> models=Generics.newArrayList();
      while (bestModels.size() > 0) {
        models.add(bestModels.poll());
      }
      Collections.reverse(models);
      double bestF1=0.0;
      int bestSize=0;
      for (int i=1; i <= models.size(); ++i) {
        System.err.println("Testing with " + i + " models averaged together");
        ShiftReduceParser parser=averageScoredModels(models.subList(0,i));
        EvaluateTreebank evaluator=new EvaluateTreebank(parser.op,null,parser);
        evaluator.testOnTreebank(devTreebank);
        double labelF1=evaluator.getLBScore();
        System.err.println("Label F1 for " + i + " models: "+ labelF1);
        if (labelF1 > bestF1) {
          bestF1=labelF1;
          bestSize=i;
        }
      }
      copyWeights(averageScoredModels(models.subList(0,bestSize)));
    }
 else {
      copyWeights(ShiftReduceParser.averageScoredModels(bestModels));
    }
  }
  if (featureFrequencies != null) {
    filterFeatures(featureFrequencies.keysAbove(op.trainOptions().featureFrequencyCutoff));
  }
  condenseFeatures();
  if (serializedPath != null) {
    try {
      IOUtils.writeObjectToFile(this,serializedPath);
    }
 catch (    IOException e) {
      throw new RuntimeIOException(e);
    }
  }
}
