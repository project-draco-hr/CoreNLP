{
  List<Tree> binarizedTrees=readBinarizedTreebank(trainTreebankPath,trainTreebankFilter);
  int nThreads=op.trainOptions.trainingThreads;
  nThreads=nThreads <= 0 ? Runtime.getRuntime().availableProcessors() : nThreads;
  MaxentTagger tagger=null;
  if (op.testOptions.preTag) {
    Timing retagTimer=new Timing();
    tagger=new MaxentTagger(op.testOptions.taggerSerializedFile);
    redoTags(binarizedTrees,tagger,nThreads);
    retagTimer.done("Retagging");
  }
  Timing transitionTimer=new Timing();
  List<List<Transition>> transitionLists=createTransitionSequences(binarizedTrees);
  for (  List<Transition> transitions : transitionLists) {
    transitionIndex.addAll(transitions);
  }
  transitionTimer.done("Converting trees into transition lists");
  System.err.println("Number of transitions: " + transitionIndex.size());
  Random random=new Random(op.trainOptions.randomSeed);
  Treebank devTreebank=null;
  if (devTreebankPath != null) {
    devTreebank=readTreebank(devTreebankPath,devTreebankFilter);
  }
  double bestScore=0.0;
  int bestIteration=0;
  PriorityQueue<ScoredObject<ShiftReduceParser>> bestModels=null;
  if (op.averagedModels > 0) {
    bestModels=new PriorityQueue<ScoredObject<ShiftReduceParser>>(op.averagedModels + 1,ScoredComparator.ASCENDING_COMPARATOR);
  }
  List<Integer> indices=Generics.newArrayList();
  for (int i=0; i < binarizedTrees.size(); ++i) {
    indices.add(i);
  }
  for (int iteration=1; iteration <= op.trainOptions.trainingIterations; ++iteration) {
    Timing trainingTimer=new Timing();
    int numCorrect=0;
    int numWrong=0;
    Collections.shuffle(indices,random);
    for (int i=0; i < indices.size(); ++i) {
      int index=indices.get(i);
      Tree tree=binarizedTrees.get(index);
      List<Transition> transitions=transitionLists.get(index);
      State state=ShiftReduceParser.initialStateFromGoldTagTree(tree);
      for (      Transition transition : transitions) {
        int transitionNum=transitionIndex.indexOf(transition);
        List<String> features=featureFactory.featurize(state);
        int predictedNum=findHighestScoringTransition(state,features,false).object();
        Transition predicted=transitionIndex.get(predictedNum);
        if (transitionNum == predictedNum) {
          numCorrect++;
        }
 else {
          numWrong++;
          for (          String feature : features) {
            List<ScoredObject<Integer>> weights=featureWeights.get(feature);
            if (weights == null) {
              weights=Generics.newArrayList();
              featureWeights.put(feature,weights);
            }
            updateWeight(weights,transitionNum,1.0);
            updateWeight(weights,predictedNum,-1.0);
          }
        }
        state=transition.apply(state);
      }
    }
    trainingTimer.done("Iteration " + iteration);
    System.err.println("While training, got " + numCorrect + " transitions correct and "+ numWrong+ " transitions wrong");
    outputStats();
    double labelF1=0.0;
    if (devTreebank != null) {
      EvaluateTreebank evaluator=new EvaluateTreebank(op,null,this,tagger);
      evaluator.testOnTreebank(devTreebank);
      labelF1=evaluator.getLBScore();
      System.err.println("Label F1 after " + iteration + " iterations: "+ labelF1);
      if (labelF1 > bestScore) {
        System.err.println("New best dev score (previous best " + bestScore + ")");
        bestScore=labelF1;
        bestIteration=iteration;
      }
 else {
        System.err.println("Failed to improve for " + (iteration - bestIteration) + " iteration(s) on previous best score of "+ bestScore);
        if (op.trainOptions.stalledIterationLimit > 0 && (iteration - bestIteration >= op.trainOptions.stalledIterationLimit)) {
          System.err.println("Failed to improve for too long, stopping training");
          break;
        }
      }
      if (bestModels != null) {
        bestModels.add(new ScoredObject<ShiftReduceParser>(this.deepCopy(),labelF1));
        if (bestModels.size() > op.averagedModels) {
          bestModels.poll();
        }
      }
    }
    if (serializedPath != null && op.trainOptions.debugOutputFrequency > 0) {
      String tempName=serializedPath.substring(0,serializedPath.length() - 7) + "-" + FILENAME.format(iteration)+ "-"+ NF.format(labelF1)+ ".ser.gz";
      try {
        IOUtils.writeObjectToFile(this,tempName);
      }
 catch (      IOException e) {
        throw new RuntimeIOException(e);
      }
    }
  }
  if (bestModels != null) {
    if (op.cvAveragedModels && devTreebank != null) {
      List<ScoredObject<ShiftReduceParser>> models=Generics.newArrayList();
      while (bestModels.size() > 0) {
        models.add(bestModels.poll());
      }
      Collections.reverse(models);
      double bestF1=0.0;
      int bestSize=0;
      for (int i=1; i < models.size(); ++i) {
        System.err.println("Testing with " + i + " models averaged together");
        ShiftReduceParser parser=averageModels(models.subList(0,i));
        EvaluateTreebank evaluator=new EvaluateTreebank(parser.op,null,parser);
        evaluator.testOnTreebank(devTreebank);
        double labelF1=evaluator.getLBScore();
        System.err.println("Label F1 for " + i + " models: "+ labelF1);
        if (labelF1 > bestF1) {
          bestF1=labelF1;
          bestSize=i;
        }
      }
      copyWeights(averageModels(models.subList(0,bestSize)));
    }
 else {
      copyWeights(ShiftReduceParser.averageModels(bestModels));
    }
  }
  condenseFeatures();
  if (serializedPath != null) {
    try {
      IOUtils.writeObjectToFile(this,serializedPath);
    }
 catch (    IOException e) {
      throw new RuntimeIOException(e);
    }
  }
}
