{
  int totalSamples=0;
  sayln("Using lambda=" + lambda);
  if (f instanceof AbstractStochasticCachingDiffUpdateFunction) {
    AbstractStochasticCachingDiffUpdateFunction func=(AbstractStochasticCachingDiffUpdateFunction)f;
    func.sampleMethod=AbstractStochasticCachingDiffFunction.SamplingMethod.Shuffled;
    totalSamples=func.dataDimension();
    if (bSize > totalSamples) {
      System.err.println("WARNING: Total number of samples=" + totalSamples + " is smaller than requested batch size="+ bSize+ "!!!");
      bSize=totalSamples;
      sayln("Using batch size=" + bSize);
    }
    if (bSize <= 0) {
      System.err.println("WARNING: Requested batch size=" + bSize + " <= 0 !!!");
      bSize=totalSamples;
      sayln("Using batch size=" + bSize);
    }
  }
  x=new double[initial.length];
  double[] testUpdateCache=null, currentRateCache=null, bCache=null;
  sumGradSquare=new double[initial.length];
  prevGrad=new double[initial.length];
  prevDeltaX=new double[initial.length];
  if (useAdaDelta) {
    sumDeltaXSquare=new double[initial.length];
    if (prior != Prior.NONE && prior != Prior.GAUSSIAN) {
      throw new UnsupportedOperationException("useAdaDelta is currently only supported for Prior.NONE or Prior.GAUSSIAN");
    }
  }
  int[][] featureGrouping=null;
  if (prior != Prior.LASSO && prior != Prior.NONE) {
    testUpdateCache=new double[initial.length];
    currentRateCache=new double[initial.length];
  }
  if (prior != Prior.LASSO && prior != Prior.RIDGE && prior != Prior.GAUSSIAN) {
    if (!(f instanceof HasFeatureGrouping)) {
      throw new UnsupportedOperationException("prior is specified to be ae-lasso or g-lasso, but function does not support feature grouping");
    }
    featureGrouping=((HasFeatureGrouping)f).getFeatureGrouping();
  }
  if (prior == Prior.sgLASSO) {
    bCache=new double[initial.length];
  }
  System.arraycopy(initial,0,x,0,x.length);
  int numBatches=1;
  if (f instanceof AbstractStochasticCachingDiffUpdateFunction) {
    if (totalSamples > 0)     numBatches=totalSamples / bSize;
  }
  boolean have_max=(maxIterations > 0 || numPasses > 0);
  if (!have_max) {
    throw new UnsupportedOperationException("No maximum number of iterations has been specified.");
  }
 else {
    maxIterations=Math.max(maxIterations,numPasses * numBatches);
  }
  sayln("       Batch size of: " + bSize);
  sayln("       Data dimension of: " + totalSamples);
  sayln("       Batches per pass through data:  " + numBatches);
  sayln("       Number of passes is = " + numPasses);
  sayln("       Max iterations is = " + maxIterations);
  Timing total=new Timing();
  Timing current=new Timing();
  total.start();
  current.start();
  int iters=0;
  double gValue=0;
  double wValue=0;
  double currentRate=0, testUpdate=0, realUpdate=0;
  List<Double> values=null;
  double oldObjVal=0;
  for (int pass=0; pass < numPasses; pass++) {
    boolean doEval=(pass > 0 && evaluateIters > 0 && pass % evaluateIters == 0);
    double evalScore=Double.NEGATIVE_INFINITY;
    if (doEval) {
      evalScore=doEvaluation(x);
      if (useEvalImprovement && !toContinue(x,evalScore))       break;
    }
    double objVal=Double.NEGATIVE_INFINITY;
    double objDelta=Double.NEGATIVE_INFINITY;
    say("Iter: " + iters + " pass "+ pass+ " batch 1 ... ");
    int numOfNonZero=0, numOfNonZeroGroup=0;
    String gSizeStr="";
    for (int batch=0; batch < numBatches; batch++) {
      iters++;
      double[] gradients=null;
      if (f instanceof AbstractStochasticCachingDiffUpdateFunction) {
        AbstractStochasticCachingDiffUpdateFunction func=(AbstractStochasticCachingDiffUpdateFunction)f;
        if (bSize == totalSamples) {
          objVal=func.valueAt(x);
          gradients=func.getDerivative();
          objDelta=objVal - oldObjVal;
          oldObjVal=objVal;
          if (values == null)           values=new ArrayList<>();
          values.add(objVal);
        }
 else {
          func.calculateStochasticGradient(x,bSize);
          gradients=func.getDerivative();
        }
      }
 else       if (f instanceof AbstractCachingDiffFunction) {
        AbstractCachingDiffFunction func=(AbstractCachingDiffFunction)f;
        gradients=func.derivativeAt(x);
      }
      if (prior == Prior.NONE || prior == Prior.GAUSSIAN) {
        for (int index=0; index < x.length; index++) {
          gValue=gradients[index];
          currentRate=computeLearningRate(index,gValue);
          wValue=x[index];
          testUpdate=wValue - (currentRate * gValue);
          realUpdate=testUpdate;
          updateX(x,index,realUpdate);
        }
      }
 else       if (prior == Prior.LASSO || prior == Prior.RIDGE) {
        double testUpdateSquaredSum=0;
        Set<Integer> paramRange=null;
        if (f instanceof HasRegularizerParamRange) {
          paramRange=((HasRegularizerParamRange)f).getRegularizerParamRange(x);
        }
 else {
          paramRange=new HashSet<>();
          for (int i=0; i < x.length; i++)           paramRange.add(i);
        }
        for (        int index : paramRange) {
          gValue=gradients[index];
          currentRate=computeLearningRate(index,gValue);
          wValue=x[index];
          testUpdate=wValue - (currentRate * gValue);
          double currentLambda=currentRate * lambda;
          if (prior == Prior.LASSO) {
            realUpdate=Math.signum(testUpdate) * pospart(Math.abs(testUpdate) - currentLambda);
            updateX(x,index,realUpdate);
            if (realUpdate != 0)             numOfNonZero++;
          }
 else           if (prior == Prior.RIDGE) {
            testUpdateSquaredSum+=testUpdate * testUpdate;
            testUpdateCache[index]=testUpdate;
            currentRateCache[index]=currentRate;
          }
        }
        if (prior == Prior.RIDGE) {
          double testUpdateNorm=Math.sqrt(testUpdateSquaredSum);
          for (int index=0; index < testUpdateCache.length; index++) {
            realUpdate=testUpdateCache[index] * pospart(1 - currentRateCache[index] * lambda / testUpdateNorm);
            updateX(x,index,realUpdate);
            if (realUpdate != 0)             numOfNonZero++;
          }
        }
      }
 else {
        for (        int[] gFeatureIndices : featureGrouping) {
          double testUpdateSquaredSum=0;
          double testUpdateAbsSum=0;
          double M=gFeatureIndices.length;
          double dm=Math.log(M);
          for (          int index : gFeatureIndices) {
            gValue=gradients[index];
            currentRate=computeLearningRate(index,gValue);
            wValue=x[index];
            testUpdate=wValue - (currentRate * gValue);
            testUpdateSquaredSum+=testUpdate * testUpdate;
            testUpdateAbsSum+=Math.abs(testUpdate);
            testUpdateCache[index]=testUpdate;
            currentRateCache[index]=currentRate;
          }
          if (prior == Prior.gLASSO) {
            double testUpdateNorm=Math.sqrt(testUpdateSquaredSum);
            boolean groupHasNonZero=false;
            for (            int index : gFeatureIndices) {
              realUpdate=testUpdateCache[index] * pospart(1 - currentRateCache[index] * lambda * dm / testUpdateNorm);
              updateX(x,index,realUpdate);
              if (realUpdate != 0) {
                numOfNonZero++;
                groupHasNonZero=true;
              }
            }
            if (groupHasNonZero)             numOfNonZeroGroup++;
          }
 else           if (prior == Prior.aeLASSO) {
            int nonZeroCount=0;
            boolean groupHasNonZero=false;
            for (            int index : gFeatureIndices) {
              double tau=currentRateCache[index] * lambda / (1 + currentRateCache[index] * lambda * M) * testUpdateAbsSum;
              realUpdate=Math.signum(testUpdateCache[index]) * pospart(Math.abs(testUpdateCache[index]) - tau);
              updateX(x,index,realUpdate);
              if (realUpdate != 0) {
                numOfNonZero++;
                nonZeroCount++;
                groupHasNonZero=true;
              }
            }
            if (groupHasNonZero)             numOfNonZeroGroup++;
          }
 else           if (prior == Prior.sgLASSO) {
            double bSquaredSum=0, b=0;
            for (            int index : gFeatureIndices) {
              b=Math.signum(testUpdateCache[index]) * pospart(Math.abs(testUpdateCache[index]) - currentRateCache[index] * alpha * lambda);
              bCache[index]=b;
              bSquaredSum+=b * b;
            }
            double bNorm=Math.sqrt(bSquaredSum);
            int nonZeroCount=0;
            boolean groupHasNonZero=false;
            for (            int index : gFeatureIndices) {
              realUpdate=bCache[index] * pospart(1 - currentRateCache[index] * (1.0 - alpha) * lambda* dm / bNorm);
              updateX(x,index,realUpdate);
              if (realUpdate != 0) {
                numOfNonZero++;
                nonZeroCount++;
                groupHasNonZero=true;
              }
            }
            if (groupHasNonZero) {
              numOfNonZeroGroup++;
            }
          }
        }
      }
      for (int index=0; index < x.length; index++) {
        prevGrad[index]=gradients[index];
      }
    }
    try {
      ArrayMath.assertFinite(x,"x");
    }
 catch (    ArrayMath.InvalidElementException e) {
      System.err.println(e.toString());
      for (int i=0; i < x.length; i++) {
        x[i]=Double.NaN;
      }
      break;
    }
    sayln(String.valueOf(numBatches) + ", n0-fCount:" + numOfNonZero+ ((prior != Prior.LASSO && prior != Prior.RIDGE) ? ", n0-gCount:" + numOfNonZeroGroup : "")+ ((evalScore != Double.NEGATIVE_INFINITY) ? ", evalScore:" + evalScore : "")+ (objVal != Double.NEGATIVE_INFINITY ? ", obj_val:" + nf.format(objVal) + ", obj_delta:"+ objDelta : ""));
    if (values != null && useAvgImprovement && iters > 5) {
      int size=values.size();
      double previousVal=(size >= 10 ? values.get(size - 10) : values.get(0));
      double averageImprovement=(previousVal - objVal) / (size >= 10 ? 10 : size);
      if (Math.abs(averageImprovement / objVal) < TOL) {
        sayln("Online Optmization completed, due to average improvement: | newest_val - previous_val | / |newestVal| < TOL ");
        break;
      }
    }
    if (iters >= maxIterations) {
      sayln("Online Optimization complete.  Stopped after max iterations");
      break;
    }
    if (total.report() >= maxTime) {
      sayln("Online Optimization complete.  Stopped after max time");
      break;
    }
  }
  if (evaluateIters > 0) {
    double evalScore=(useEvalImprovement ? doEvaluation(xBest) : doEvaluation(x));
    sayln("final evalScore is: " + evalScore);
  }
  sayln("Completed in: " + Timing.toSecondsString(total.report()) + " s");
  return (useEvalImprovement ? xBest : x);
}
