{
  if (alreadySetUp) {
    return;
  }
  if (wordIgnoreRegex != null && !wordIgnoreRegex.isEmpty())   ignoreWordRegex=Pattern.compile(wordIgnoreRegex);
  for (  String label : labelDictionary.keySet()) {
    env.put(label,TokenSequencePattern.getNewEnv());
    for (    Entry<String,Class<? extends Key<String>>> en : this.answerClass.entrySet()) {
      env.get(label).bind(en.getKey(),en.getValue());
    }
    for (    Entry<String,Class> en : generalizeClasses.entrySet())     env.get(label).bind(en.getKey(),en.getValue());
  }
  Redwood.log(Redwood.DBG,channelNameLogger,"Running with debug output");
  stopWords=new HashSet<String>();
  Redwood.log(ConstantsAndVariables.minimaldebug,channelNameLogger,"Reading stop words from " + stopWordsPatternFiles);
  for (  String stopwfile : stopWordsPatternFiles.split("[;,]"))   stopWords.addAll(IOUtils.linesFromFile(stopwfile));
  englishWords=new HashSet<String>();
  System.out.println("Reading english words from " + englishWordsFiles);
  for (  String englishWordsFile : englishWordsFiles.split("[;,]"))   englishWords.addAll(IOUtils.linesFromFile(englishWordsFile));
  if (commonWordsPatternFiles != null) {
    commonEngWords=Collections.synchronizedSet(new HashSet<String>());
    for (    String file : commonWordsPatternFiles.split("[;,]"))     commonEngWords.addAll(IOUtils.linesFromFile(file));
  }
  if (otherSemanticClassesFiles != null) {
    if (otherSemanticClasses == null)     otherSemanticClasses=Collections.synchronizedSet(new HashSet<String>());
    for (    String file : otherSemanticClassesFiles.split("[;,]")) {
      for (      String w : IOUtils.linesFromFile(file)) {
        String[] t=w.split("\\s+");
        if (t.length <= this.numWordsCompound)         otherSemanticClasses.add(w);
      }
    }
    System.out.println("Size of othersemantic class variables is " + otherSemanticClasses.size());
  }
 else {
    otherSemanticClasses=Collections.synchronizedSet(new HashSet<String>());
    System.out.println("Size of othersemantic class variables is " + 0);
  }
  String stopStr="/";
  int i=0;
  for (  String s : stopWords) {
    if (i > 0)     stopStr+="|";
    stopStr+=Pattern.quote(s.replaceAll("\\\\","\\\\\\\\"));
    i++;
  }
  stopStr+="/";
  for (  String label : labelDictionary.keySet()) {
    env.get(label).bind("$FILLER","/" + StringUtils.join(fillerWords,"|") + "/");
    env.get(label).bind("$STOPWORD",stopStr);
    env.get(label).bind("$MOD","[{tag:/JJ.*/}]");
    if (matchLowerCaseContext)     env.get(label).setDefaultStringPatternFlags(Pattern.CASE_INSENSITIVE);
    env.get(label).bind("OTHERSEM",PatternsAnnotations.OtherSemanticLabel.class);
    env.get(label).bind("grandparentparsetag",CoreAnnotations.GrandparentAnnotation.class);
  }
  if (wordClassClusterFile != null) {
    wordClassClusters=new HashMap<String,Integer>();
    for (    String line : IOUtils.readLines(wordClassClusterFile)) {
      String[] t=line.split("\t");
      wordClassClusters.put(t[0],Integer.parseInt(t[1]));
    }
  }
  if (generalWordClassClusterFile != null) {
    setGeneralWordClassClusters(new HashMap<String,Integer>());
    for (    String line : IOUtils.readLines(generalWordClassClusterFile)) {
      String[] t=line.split("\t");
      getGeneralWordClassClusters().put(t[0],Integer.parseInt(t[1]));
    }
  }
  if (targetAllowedTagsInitialsStr != null) {
    allowedTagsInitials=new HashMap<String,Set<String>>();
    for (    String labelstr : targetAllowedTagsInitialsStr.split(";")) {
      String[] t=labelstr.split(",");
      Set<String> st=new HashSet<String>();
      for (int j=1; j < t.length; j++)       st.add(t[j]);
      allowedTagsInitials.put(t[0],st);
    }
  }
  if (useTargetNERRestriction && targetAllowedNERs != null) {
    allowedNERsforLabels=new HashMap<String,Set<String>>();
    for (    String labelstr : targetAllowedNERs.split(";")) {
      String[] t=labelstr.split(",");
      Set<String> st=new HashSet<String>();
      for (int j=1; j < t.length; j++)       st.add(t[j]);
      allowedNERsforLabels.put(t[0],st);
    }
  }
  alreadySetUp=true;
}
