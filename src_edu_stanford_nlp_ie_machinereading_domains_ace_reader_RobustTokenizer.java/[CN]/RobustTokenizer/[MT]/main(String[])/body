{
  if (argv.length != 1) {
    System.err.println("Usage: java edu.stanford.nlp.ie.machinereading.common.RobustTokenizer <file to tokenize>");
    System.exit(1);
  }
  BufferedReader is=new BufferedReader(new FileReader(argv[0]));
  int ch;
  StringBuffer buffer=new StringBuffer();
  while ((ch=is.read()) != -1)   buffer.append((char)ch);
  RobustTokenizer<Word> t=new RobustTokenizer<Word>(buffer.toString());
  List<Word> tokens=t.tokenize();
  for (int i=0; i < tokens.size(); i++) {
    System.out.println(tokens.get(i));
  }
}
