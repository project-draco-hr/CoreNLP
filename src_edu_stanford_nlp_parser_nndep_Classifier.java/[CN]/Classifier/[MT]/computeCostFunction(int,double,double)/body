{
  validateTraining();
  List<Example> examples=Util.getRandomSubList(dataset.examples,batchSize);
  Set<Integer> toPreCompute=getPreComputeTokens(examples);
  double percentagePreComputed=toPreCompute.size() / (float)config.numPreComputed;
  System.err.printf("Percent actually necessary to pre-compute: %f%%%n",percentagePreComputed * 100);
  smallMap=new HashMap<>(toPreCompute.size());
  int newId=0;
  for (  int id : toPreCompute) {
    smallMap.put(preMap.get(id),newId);
    newId++;
  }
  preCompute(smallMap);
  FeedforwardParams params=new FeedforwardParams(regParameter,dropOutProb,W1,b1,W2,E,saved);
  int numChunks=config.trainingThreads;
  List<Collection<Example>> chunks=CollectionUtils.partitionIntoFolds(examples,numChunks);
  for (  Collection<Example> chunk : chunks)   jobHandler.put(new Pair<>(chunk,params));
  jobHandler.join(false);
  Cost cost=null;
  while (jobHandler.peek()) {
    Cost otherCost=jobHandler.poll();
    if (cost == null)     cost=otherCost;
 else     cost.merge(otherCost);
  }
  if (cost == null)   return null;
  cost.backpropSaved(smallMap);
  return cost;
}
