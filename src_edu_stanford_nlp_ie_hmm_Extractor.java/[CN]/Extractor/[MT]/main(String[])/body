{
  Structure.rand=new Random(0);
  if (args.length == 0) {
    dieUsage(null);
  }
  int arg=0;
  boolean verbose=false;
  if (args[arg].equals("-v")) {
    verbose=true;
    arg++;
  }
  if (verbose) {
    String hostname;
    try {
      hostname=InetAddress.getLocalHost().getHostName();
    }
 catch (    Exception e) {
      hostname=null;
    }
    System.err.print("Started Extractor");
    if (hostname != null) {
      System.err.print(" on " + hostname);
    }
    System.err.println(" at " + new Date());
  }
  if (arg == args.length) {
    dieUsage("must specify properties file");
  }
  Properties props=new Properties(getDefaultProperties());
  try {
    props.load(new FileInputStream(args[arg]));
  }
 catch (  Exception e) {
    dieUsage("error loading properties file: " + e);
  }
  if (props.getProperty("description") != null) {
    System.err.println("Description of properties used: " + props.getProperty("description"));
  }
  if (verbose) {
    props.list(System.err);
  }
  String dataFilename=props.getProperty("dataFile");
  String allTargetFields=props.getProperty("targetFields");
  if (allTargetFields == null || allTargetFields.length() == 0) {
    dieUsage("must specify at least one target field");
  }
  String[] targetFields=allTargetFields.split(" ");
  boolean bestAnswerOnly=Boolean.parseBoolean(props.getProperty("bestAnswerOnly"));
  boolean useFirstAnswers="first_match".equals(props.getProperty("singleMatchStrategy"));
  boolean discardHtml=!"false".equals(props.getProperty("discardHtml"));
  String hmmType=props.getProperty("hmmType");
  if (hmmType != null) {
    boolean useMerged=hmmType.equals("merged");
    boolean useSMerged=hmmType.equals("s-merged");
    boolean useLearned=hmmType.equals("learned");
    Structure structure=null;
    if (!useMerged && !useSMerged && !useLearned&& !hmmType.equals("target")&& !hmmType.equals("context")&& !hmmType.equals("s-context")) {
      try {
        structure=getStructure(hmmType,props);
      }
 catch (      IllegalArgumentException e) {
        dieUsage("invalid hmmType: " + hmmType);
      }
    }
    int numSlices=Integer.parseInt(props.getProperty("cvSlices"));
    boolean runTest=(numSlices > 0);
    String testFilename=props.getProperty("testFile");
    if (testFilename != null) {
      numSlices=0;
      runTest=true;
    }
    if (hmmType.equals("target") || hmmType.equals("context") || hmmType.equals("s-context")) {
      runTest=false;
    }
    int numFolds, startFold, endFold;
    if (numSlices == 0) {
      numFolds=1;
      startFold=1;
      endFold=1;
    }
 else {
      numFolds=numSlices;
      if (props.getProperty("cvFolds") != null) {
        numFolds=Integer.parseInt(props.getProperty("cvFolds"));
      }
      startFold=Integer.parseInt(props.getProperty("startFold"));
      if (startFold + numFolds - 1 > numSlices) {
        numFolds=numSlices - startFold + 1;
      }
      endFold=startFold + numFolds - 1;
    }
    File splitdir=null;
    if (props.getProperty("splitdir") != null) {
      splitdir=new File(props.getProperty("splitdir"));
    }
    File basedir=null;
    if (props.getProperty("basedir") != null) {
      basedir=new File(props.getProperty("basedir"));
    }
    if (verbose) {
switch (numSlices) {
case 0:
        System.err.println("Training on entire corpus");
      break;
case 1:
    System.err.println("WARNING: 1 slice -> testing on entire corpus");
  break;
default :
System.err.println("Testing on 1/" + numSlices + " of the corpus for each fold");
}
}
double delta=(numSlices == 0 ? 0 : 1.0 / numSlices);
int numTests=((useMerged || hmmType.equals("context")) ? 1 : targetFields.length);
int numCandidates=Integer.parseInt(props.getProperty("numCandidates"));
boolean trainConditionally=props.getProperty("trainType").equals("conditional");
boolean evaluateOnLikelihood=props.getProperty("candidateEvaluation").equals("likelihood");
double heldOutFraction;
if (numCandidates == 1 || evaluateOnLikelihood) {
heldOutFraction=0.0;
}
 else {
heldOutFraction=Double.parseDouble(props.getProperty("heldOutFraction"));
}
if (hmmType.equals("target") || hmmType.equals("context") || hmmType.equals("s-context")) {
evaluateOnLikelihood=true;
}
PRStatsManager<String> manager=new PRStatsManager<String>();
List<Pair<String,Double>> spread=new LinkedList<Pair<String,Double>>();
for (int i=0; i < numTests; i++) {
String[] curTargets;
if (useMerged || hmmType.equals("context")) {
curTargets=targetFields;
}
 else {
System.err.println("Training and testing on " + targetFields[i] + " field...");
curTargets=new String[]{targetFields[i]};
}
Corpus data=null;
if (splitdir == null) {
if (basedir != null) {
if (!basedir.isDirectory()) {
  dieUsage(basedir + "is not a directory");
}
File[] dataFiles=basedir.listFiles(new FileFilter(){
  public boolean accept(  File file){
    return file.isFile();
  }
}
);
ArrayList<File> dataFileList=new ArrayList<File>();
for (int j=0; j < dataFiles.length; j++) {
  dataFileList.add(dataFiles[j]);
}
data=new Corpus(curTargets);
data.load(dataFileList,FreitagIECollectionIterator.factory(curTargets,discardHtml));
}
 else {
if (dataFilename == null) {
  dieUsage("must specify a datafile");
}
if (!new File(dataFilename).canRead()) {
  dieUsage("cannot read datafile: " + dataFilename);
}
data=new Corpus(dataFilename,curTargets,discardHtml);
}
}
for (int j=startFold; j <= endFold; j++) {
if (startFold != 0 || numFolds > 1) {
System.err.println("------ Fold " + j + " of "+ endFold+ ": ------");
}
double offset=(j - 1) * delta;
Corpus trainDocs, heldOutDocs, testDocs;
if (testFilename != null) {
if (verbose) {
  System.err.println("Using separate test file: " + testFilename);
}
Corpus[] corpora=(Corpus[])data.split(0,new double[]{1.0 - heldOutFraction,heldOutFraction});
trainDocs=corpora[0];
heldOutDocs=corpora[1];
testDocs=new Corpus(testFilename,curTargets);
}
 else if (splitdir == null) {
double trainFraction=1.0 - delta;
Corpus[] corpora=(Corpus[])data.split(offset,new double[]{trainFraction * (1.0 - heldOutFraction),trainFraction * heldOutFraction,delta});
trainDocs=corpora[0];
heldOutDocs=corpora[1];
testDocs=corpora[2];
}
 else {
File trainFile=new File(splitdir,"train." + j);
FileArrayList trainFiles=new FileArrayList(trainFile,basedir);
trainDocs=new Corpus(curTargets);
File testFile=new File(splitdir,"test." + j);
FileArrayList testFiles=new FileArrayList(testFile,basedir);
testDocs=new Corpus(curTargets);
try {
  if (verbose) {
    System.err.println("Reading in " + trainFiles.size() + " training files from "+ trainFile);
  }
  trainDocs.load(trainFiles,FreitagIECollectionIterator.factory(curTargets));
}
 catch (Exception e) {
  System.err.println("Error reading training docs");
  e.printStackTrace();
}
Corpus[] corpora=(Corpus[])trainDocs.split(0,new double[]{1.0 - heldOutFraction,heldOutFraction});
trainDocs=corpora[0];
heldOutDocs=corpora[1];
try {
  if (verbose) {
    System.err.println("Reading in " + testFiles.size() + " test files from "+ testFile);
  }
  testDocs.load(testFiles,FreitagIECollectionIterator.factory(curTargets));
}
 catch (Exception e) {
  System.err.println("Error reading training docs");
  e.printStackTrace();
}
}
System.err.println("Training HMM of type " + hmmType + " on "+ trainDocs.size()+ " docs...");
HMM hmm=null;
double bestScore=Double.NEGATIVE_INFINITY;
if (verbose && numCandidates > 1) {
System.err.print("Training " + numCandidates + " candidate HMMs, evaluated on ");
if (evaluateOnLikelihood) {
  System.err.println("training " + (trainConditionally ? "conditional" : "joint") + " likelihood");
}
 else {
  System.err.println("held out F1 (" + (heldOutFraction * 100) + "% of training data)");
}
}
for (int k=0; k < numCandidates; k++) {
if (verbose && numCandidates > 1) {
  System.err.println("Training candidate HMM " + (k + 1) + " of "+ numCandidates);
}
HMM candidateHMM;
if (useMerged || useSMerged) {
  candidateHMM=MergeTrainer.mergeTrain(trainDocs,props,verbose);
}
 else if (useLearned) {
  structure=new StructureLearner().learnStructure(trainDocs,props,verbose);
  candidateHMM=new HMM(structure,HMM.REGULAR_HMM);
}
 else if (hmmType.equals("context") || hmmType.equals("s-context")) {
  candidateHMM=new ContextTrainer().train(trainDocs,props,curTargets,verbose);
}
 else if (hmmType.equals("target")) {
  candidateHMM=new TargetTrainer().train(trainDocs,targetFields[i],props,verbose);
}
 else {
  candidateHMM=new HMM(structure,HMM.REGULAR_HMM);
  if (josephAtPlay) {
    candidateHMM.setTestCorpus(testDocs);
  }
  candidateHMM.train(trainDocs,props,verbose);
}
double candidateScore=0;
if (numCandidates > 1) {
  if (evaluateOnLikelihood) {
    candidateScore=trainConditionally ? candidateHMM.logConditionalLikelihood(trainDocs) : candidateHMM.logLikelihood(trainDocs);
  }
 else {
    candidateScore=new HMMTester(candidateHMM).test(heldOutDocs,props,bestAnswerOnly,useFirstAnswers,false);
  }
  if (verbose) {
    System.err.println("Score for candidate HMM " + (k + 1) + " of "+ numCandidates+ ": "+ candidateScore);
  }
}
if (k == 0 || candidateScore > bestScore) {
  hmm=candidateHMM;
  bestScore=candidateScore;
  if (verbose && numCandidates > 1) {
    System.err.println("Candidate " + (k + 1) + " is best HMM so far");
  }
}
}
if (hmm == null) {
throw (new IllegalStateException("No candidate HMM was selected!"));
}
if (!evaluateOnLikelihood && heldOutDocs.size() > 0) {
if (verbose) {
  System.err.println("Retraining best candidate HMM on held out data");
}
props.setProperty("initEmissions","false");
trainDocs.addAll(heldOutDocs);
hmm.train(trainDocs,new Corpus(),props,verbose);
props.setProperty("initEmissions","true");
}
try {
if (props.getProperty("hmmOutfilePrefix") != null) {
  String prefix=props.getProperty("hmmOutfilePrefix");
  if (hmmType.equals("context")) {
    prefix+=".context";
  }
 else   if (hmmType.equals("s-context")) {
    prefix+="." + targetFields[i] + ".context";
  }
 else   if (hmmType.equals("target")) {
    prefix+="." + targetFields[i];
  }
  serializeHMM(hmm,prefix,numFolds == 1 ? 0 : j);
}
}
 catch (Exception e) {
e.printStackTrace();
}
if (runTest) {
System.err.println("Testing HMM on " + testDocs.size() + " documents...");
HMMTester hmmt=new HMMTester(hmm);
hmmt.test(testDocs,props,bestAnswerOnly,useFirstAnswers,verbose);
manager.addStats(overallStatsName,hmmt.getAggregateStats());
for (int t=0; t < curTargets.length; t++) {
  manager.addStats(curTargets[t],hmmt.getTargetFieldStats(curTargets[t]));
}
}
}
if (numFolds > 1 && runTest && !useMerged) {
double averageF1=manager.getAverageFMeasure(targetFields[i]);
System.err.println("Average F1 for " + targetFields[i] + " across "+ numFolds+ " folds: "+ averageF1);
spread.add(new Pair<String,Double>(targetFields[i],new Double(averageF1)));
}
}
if ((useMerged || targetFields.length > 1) && runTest) {
double grandAverageF1=manager.getAverageFMeasure(overallStatsName);
System.err.println("------ Summary for all fields: ------");
System.err.println("Grand Average F1 across " + targetFields.length + " fields: "+ grandAverageF1);
for (int i=0; i < targetFields.length; i++) {
System.err.println("Grand Average F1 for " + targetFields[i] + ": "+ manager.getAverageFMeasure(targetFields[i]));
}
System.err.println("Spreadsheet-friendly summary:");
Pair<String,Double> avePair=new Pair<String,Double>("Average",new Double(grandAverageF1));
spread.add(avePair);
for (Iterator<Pair<String,Double>> i=spread.iterator(); i.hasNext(); ) {
Pair p=i.next();
System.err.print(p.first());
if (i.hasNext()) {
System.err.print("\t");
}
 else {
System.err.println();
}
}
for (Iterator<Pair<String,Double>> i=spread.iterator(); i.hasNext(); ) {
Pair p=i.next();
System.err.print(p.second());
if (i.hasNext()) {
System.err.print("\t");
}
 else {
System.err.println();
}
}
}
 else if (numFolds == 1 && runTest) {
double grandAverageF1=manager.getAverageFMeasure(overallStatsName);
System.err.println("Average F1 for " + targetFields[0] + ": "+ grandAverageF1);
}
}
 else if (props.getProperty("hmmFile") != null) {
File hmmFile=new File(props.getProperty("hmmFile"));
if (!hmmFile.canRead()) {
dieUsage("cannot read hmmFile: " + hmmFile);
}
try {
System.err.println("Loading HMM from " + hmmFile + "...");
HMM hmm=(HMM)new ObjectInputStream(new FileInputStream(hmmFile)).readObject();
if (verbose) {
hmm.printProbs();
}
Corpus data=new Corpus(dataFilename,targetFields,discardHtml);
if (data.size() > 0) {
HMMTester hmmt=new HMMTester(hmm);
hmmt.test(data,props,bestAnswerOnly,useFirstAnswers,verbose);
System.err.println("Average F1 across " + targetFields.length + " fields: "+ hmmt.getAggregateStats().getFMeasure());
for (int i=0; i < targetFields.length; i++) {
System.err.println("Average F1 for " + targetFields[i] + ": "+ hmmt.getTargetFieldStats(targetFields[i]).getFMeasure());
}
}
 else {
System.err.println("Extracting best answers from text in " + dataFilename + "...");
String text=IOUtils.slurpFile(new File(dataFilename));
Map bestAnswerByType=useFirstAnswers ? hmm.firstAnswers(text) : hmm.bestAnswers(text);
Iterator iter=bestAnswerByType.keySet().iterator();
while (iter.hasNext()) {
Integer type=(Integer)iter.next();
System.err.println("Best answer for type " + type + ": "+ bestAnswerByType.get(type));
}
}
}
 catch (Exception e) {
e.printStackTrace();
}
}
 else {
dieUsage("must specify -train or -load");
}
}
