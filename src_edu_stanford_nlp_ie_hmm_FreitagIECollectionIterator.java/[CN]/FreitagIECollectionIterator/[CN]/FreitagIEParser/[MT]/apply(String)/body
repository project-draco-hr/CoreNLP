{
  if (text == null) {
    return null;
  }
  TypedTaggedDocument<L> doc=new TypedTaggedDocument<L>(targetFields);
  String[][] tags=new String[targetFields.length][];
  for (int i=1; i < targetFields.length; i++) {
    tags[i]=new String[NUM_MARKUP_FORMS];
    tags[i][0]="<" + targetFields[i] + ">";
    tags[i][1]="<tag name=\"" + targetFields[i] + "\" value=\"start\"/>";
  }
  TaggedStreamTokenizer tokenizer=makeTokenizer(new StringReader(text));
  if (tokenizer == null) {
    throw (new IllegalStateException("Unable to create tokenizer"));
  }
  List<Word> words=new ArrayList<Word>();
  tokenizer.setDiscardHtml(discardHtml);
  try {
    while (tokenizer.ttype != TaggedStreamTokenizer.TT_EOF) {
      if (tokenizer.sval != null) {
        int newtype=-1;
        boolean set=false;
        if (tokenizer.ttype != TaggedStreamTokenizer.TT_TARGET_WORD) {
          newtype=0;
        }
 else {
          for (int t=1; t < targetFields.length && !set; t++) {
            for (int u=0; u < tags[t].length && !set; u++) {
              if (tags[t][u].equals(tokenizer.attr)) {
                set=true;
              }
              newtype=t;
            }
          }
        }
        words.add(new TypedTaggedWord(tokenizer.sval,newtype));
      }
      tokenizer.nextToken();
    }
    doc.addAll(words);
  }
 catch (  Exception e) {
    e.printStackTrace();
  }
  return (doc);
}
