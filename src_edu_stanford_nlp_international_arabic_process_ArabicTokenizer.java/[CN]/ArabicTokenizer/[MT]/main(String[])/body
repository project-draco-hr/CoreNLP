{
  if (args.length > 0 && args[0].contains("help")) {
    System.err.printf("Usage: java %s [OPTIONS] < file%n",ArabicTokenizer.class.getName());
    System.err.printf("%nOptions:%n");
    log.info("   -help : Print this message. See javadocs for all normalization options.");
    log.info("   -atb  : Tokenization for the parsing experiments in Green and Manning (2010)");
    System.exit(-1);
  }
  final Properties tokenizerOptions=StringUtils.argsToProperties(args);
  final TokenizerFactory<CoreLabel> tf=tokenizerOptions.containsKey("atb") ? ArabicTokenizer.atbFactory() : ArabicTokenizer.factory();
  for (  String option : tokenizerOptions.stringPropertyNames()) {
    tf.setOptions(option);
  }
  tf.setOptions("tokenizeNLs");
  int nLines=0;
  int nTokens=0;
  try {
    final String encoding="UTF-8";
    Tokenizer<CoreLabel> tokenizer=tf.getTokenizer(new InputStreamReader(System.in,encoding));
    boolean printSpace=false;
    while (tokenizer.hasNext()) {
      ++nTokens;
      String word=tokenizer.next().word();
      if (word.equals(ArabicLexer.NEWLINE_TOKEN)) {
        ++nLines;
        printSpace=false;
        System.out.println();
      }
 else {
        if (printSpace)         System.out.print(" ");
        System.out.print(word);
        printSpace=true;
      }
    }
  }
 catch (  UnsupportedEncodingException e) {
    e.printStackTrace();
  }
  System.err.printf("Done! Tokenized %d lines (%d tokens)%n",nLines,nTokens);
}
