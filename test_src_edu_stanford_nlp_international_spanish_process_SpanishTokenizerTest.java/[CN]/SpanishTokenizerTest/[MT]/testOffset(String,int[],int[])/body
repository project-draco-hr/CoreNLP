{
  TokenizerFactory<CoreLabel> tf=SpanishTokenizer.ancoraFactory();
  Tokenizer<CoreLabel> tokenizer=tf.getTokenizer(new StringReader(input));
  List<CoreLabel> tokens=tokenizer.tokenize();
  assertEquals("Number of tokens doesn't match reference '" + input + "'",beginOffsets.length,tokens.size());
  for (int i=0; i < beginOffsets.length; i++) {
    assertEquals("Char begin offset of word " + i + " deviates from reference '"+ input+ "'",beginOffsets[i],tokens.get(i).beginPosition());
    assertEquals("Char end offset of word " + i + " deviates from reference '"+ input+ "'",endOffsets[i],tokens.get(i).endPosition());
  }
}
