{
  Corpus originalTrain;
  if (josephStuff) {
    originalTrain=train;
  }
  if (props == null) {
    props=Extractor.getDefaultProperties();
  }
  if (feat == null) {
    try {
      String unkFeature=props.getProperty("unkFeature");
      if (verbose) {
        System.err.println("Instantiating Feature class: " + unkFeature);
      }
      feat=(Feature)Class.forName(unkFeature).newInstance();
    }
 catch (    Exception e) {
      if (verbose) {
        System.err.println("Feature class specified in properties file not found: " + e);
        System.err.println("Using default edu.stanford.nlp.ie.hmm.NumAndCapFeature instead.");
      }
      feat=new NumAndCapFeature();
    }
  }
  boolean shrinkage=(props.getProperty("shrinkage") != null);
  unseenMode=parseUnseenMode(props.getProperty("unseenMode"));
  unkModel=parseUnkModel(props.getProperty("unkModel"));
  unseenProbSource=parseSource(props.getProperty("unseenProbSource"));
  featureSource=parseSource(props.getProperty("featureSource"));
  boolean initEmissions=props.getProperty("initEmissions").equalsIgnoreCase("true");
  double pseudoTransitionsCount=Double.parseDouble(props.getProperty("pseudoTransitionsCount"));
  double pseudoEmissionsCount=Double.parseDouble(props.getProperty("pseudoEmissionsCount"));
  double pseudoUnknownsCount=Double.parseDouble(props.getProperty("pseudoUnknownsCount"));
  if (heldOut == null && (shrinkage || (unseenMode == UNSEENMODE_HOLD_OUT_MASS && (unseenProbSource == SOURCE_HELD_OUT || featureSource == SOURCE_HELD_OUT)))) {
    if (verbose) {
      System.err.println("Splitting the training corpus because heldOut was null");
    }
    double splitPoint=1.0 - DEFAULT_HELD_OUT_FRAC;
    heldOut=(Corpus)train.splitRange(splitPoint,1.0);
    train=(Corpus)train.splitRange(0.0,splitPoint);
  }
  if (unseenMode == UNSEENMODE_UNK_LOW_COUNTS) {
    boolean decomp=(unkModel == UNKMODEL_FEATURAL_DECOMP);
    ClassicCounter<String> fullVocab=new ClassicCounter<String>();
    if (train != null) {
      Counters.addInPlace(fullVocab,train.getVocab());
    }
    if (heldOut != null) {
      Counters.addInPlace(fullVocab,heldOut.getVocab());
    }
    Set frequentWords=Counters.keysAbove(fullVocab,(double)2);
    if (train != null) {
      train=new UnknownWordCollapser(frequentWords,decomp,feat).processCorpus(train);
    }
    if (heldOut != null) {
      heldOut=new UnknownWordCollapser(frequentWords,decomp,feat).processCorpus(heldOut);
    }
  }
  targetFields=train.getTargetFields();
  if (verbose) {
    System.err.println("Training HMM on " + train.size() + " documents with targets");
    System.err.println("----------------------------");
    for (int i=0; i < targetFields.length; i++) {
      System.err.println(i + ": " + targetFields[i]);
    }
    System.err.println("----------------------------");
    printTransitions();
  }
  if (sanityCheck) {
    checkStochasticMatrix(states);
  }
  hmmt=new HMMTrainer(verbose,pseudoTransitionsCount,pseudoEmissionsCount,pseudoUnknownsCount);
  if (train != null) {
    hmmt.setTrainingCorpus(train);
  }
  hmmt.initEmissions(initEmissions);
  if (props.getProperty("trainType").equals("conditional")) {
    Minimizer cgm;
    if (verbose) {
      cgm=new CGMinimizer(new HMM.HMMConditionalTrainingMonitorFunction(hmmt));
    }
 else {
      cgm=new CGMinimizer();
    }
    ConstrainedMinimizer<DiffFunction> ccgm=new PenaltyConstrainedMinimizer(cgm);
    double tol=1e-4;
    HMMConditionalTrainingMassPenaltyFunction penaltyFunction=new HMMConditionalTrainingMassPenaltyFunction(hmmt,states.length);
    hmmt.setSigmaSquared(Integer.parseInt(props.getProperty("sigmaSquared")));
    double penaltyTolerance=penaltyFunction.getIdealTotalMass() * 0.1;
    double[] minimum=ccgm.minimize(hmmt,tol,new DiffFunction[]{penaltyFunction},penaltyTolerance,new DiffFunction[0],0,hmmt.initialParams());
    if (verbose) {
      System.err.println("Final score for minimum conditional paramters: " + hmmt.valueAt(minimum));
    }
    hmmt.applyParams(minimum);
  }
 else   if ("entropicPriorMAP".equals(props.getProperty("trainType"))) {
    hmmt.trainEntropicPriorMAP();
  }
 else {
    hmmt.forwardBackward();
    if (josephStuff) {
      props.setProperty("trainType","conditional");
      props.setProperty("initEmissions","false");
      for (int i=0; i < 4; i++) {
switch (i) {
case 0:
          System.err.println("$$$ Training conditionally before any EM iterations");
        break;
case 1:
      System.err.println("$$$ Training conditionally after 1 round of EM");
    break;
case 2:
  System.err.println("$$$ Training conditionally after best round of EM");
break;
case 3:
System.err.println("$$$ Training conditionally after last round of EM");
break;
}
setParams(hmmt.startCondParams[i]);
train(originalTrain,null,props,verbose);
}
props.setProperty("trainType","joint");
props.setProperty("initEmissions","true");
}
}
if (heldOut != null && heldOut.size() > 0) {
if (verbose) {
printStates(states);
}
boolean useSingletons=unseenProbSource == SOURCE_SINGLETONS;
Corpus docs=useSingletons ? train : heldOut;
hmmt.estimateShrinkUnseen(docs,useSingletons,shrinkage,unseenMode == UNSEENMODE_HOLD_OUT_MASS && unseenProbSource == SOURCE_HELD_OUT);
props.setProperty("initEmissions","false");
train.addAll(heldOut);
if (verbose) {
System.err.println("Retraining on held-out docs");
}
train(train,new Corpus(),props,verbose);
props.setProperty("initEmissions",String.valueOf(initEmissions));
}
if (verbose) {
printStates(states);
}
return hmmt;
}
