{
  boolean converged=false;
  boolean likelihoodConverged=false;
  int numIterations=0;
  List params=new ArrayList();
  List f1s=new ArrayList();
  double lastConstrainedLogLikelihood=0.0;
  double logLikeImprove=0.0;
  double lastLogLikeDiff=0.0;
  while (numIterations < MAX_ITER) {
    checkNormalized();
    if (josephStuff) {
      params.add(getParams());
    }
    double logLike=expectations(true,true);
    if (numIterations > 0) {
      logLikeImprove=(lastConstrainedLogLikelihood == 0.0) ? 0.0 : (lastConstrainedLogLikelihood - logLike) / lastConstrainedLogLikelihood;
      likelihoodConverged=logLikeImprove < LL_CONVERGE_SIZE && (lastConstrainedLogLikelihood - logLike) < lastLogLikeDiff;
      lastLogLikeDiff=lastConstrainedLogLikelihood - logLike;
      if (logLikeImprove < -LL_CONVERGE_SIZE) {
        System.err.println("expectations: EM MONOTONICITY FAILURE!");
      }
    }
    if (verbose) {
      NumberFormat nf=NumberFormat.getNumberInstance();
      nf.setMaximumFractionDigits(3);
      System.err.print("Train loglike after " + numIterations + " joint reest. log P(O,C|mu) = "+ nf.format(logLike));
      if (numIterations > 0) {
        System.err.print(" [" + nf.format(logLikeImprove * 100) + "% change]");
      }
      System.err.println();
      System.err.println("Training CLL: " + nf.format(logConditionalLikelihood(trainDocs)));
    }
    lastConstrainedLogLikelihood=logLike;
    if (josephStuff && verbose) {
      System.err.println("log likelihood on training data after " + numIterations + " iterations of joint training: "+ logLike);
      System.err.println("conditional log likelihood on training data after " + numIterations + " iterations of joint training: "+ logConditionalLikelihood(trainDocs));
      double f1=new HMMTester(getHMM()).test(trainDocs,null,true,false,false);
      System.err.println("F1 on training data after " + numIterations + " iterations of joint training: "+ f1);
      f1s.add(new Double(f1));
      if (testDocs != null) {
        System.err.println("log likelihood on test data after " + numIterations + " iterations of joint training: "+ logLikelihood(testDocs,true,true));
        System.err.println("conditional log likelihood on test data after " + numIterations + " iterations of joint training: "+ logConditionalLikelihood(testDocs));
        System.err.println("F1 on test data after " + numIterations + " iterations of joint training: "+ new HMMTester(getHMM()).test(testDocs,null,true,false,false));
      }
    }
    if (numIterations >= MIN_ITER && convergenceOnLikelihood && likelihoodConverged) {
      converged=true;
      break;
    }
    boolean parametersConverged=maximize();
    numIterations++;
    if (verbose) {
      System.err.println("Parameter reestimate " + (numIterations) + ". Max Change = "+ globalMaxChange);
      printTransitions();
    }
    if (numIterations >= MIN_ITER && !convergenceOnLikelihood && parametersConverged) {
      converged=true;
      break;
    }
  }
  if (verbose) {
    if (converged) {
      System.err.println("Converged after " + numIterations + " iterations.");
    }
 else {
      System.err.println("Stopping after " + MAX_ITER + " iterations.");
    }
  }
  if (josephStuff) {
    int bestIteration=0;
    double bestF1=Double.NEGATIVE_INFINITY;
    int window=1;
    for (int i=window; i < numIterations - window; i++) {
      double avgF1=0;
      for (int j=i - window; j <= i + window; j++) {
        avgF1+=((Double)f1s.get(j)).doubleValue();
      }
      avgF1/=(window * 2 + 1);
      if (avgF1 > bestF1) {
        bestF1=avgF1;
        bestIteration=i;
      }
    }
    System.err.println("Using parameters from iteration " + bestIteration + " of "+ numIterations+ " (best training F1)");
    getHMM().setParams((double[])params.get(bestIteration));
    startCondParams[0]=(double[])params.get(0);
    startCondParams[1]=(double[])params.get(1);
    startCondParams[2]=(double[])params.get(bestIteration);
    startCondParams[3]=(double[])params.get(params.size() - 1);
  }
}
