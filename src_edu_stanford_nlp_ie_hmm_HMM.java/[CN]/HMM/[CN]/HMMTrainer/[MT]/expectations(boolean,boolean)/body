{
  if (respectTypes) {
    badDocs=new HashSet();
  }
  totalP=new double[numStates][numStates];
  totalFrom=new double[numStates];
  totalTargetOD=new double[targetFields.length];
  totalSeenP=new double[numStates];
  totalParentSeenP=new double[targetFields.length];
  for (int i=0; i < numStates; i++) {
    totalOP[i]=new ClassicCounter();
    featureMaps[i]=new FeatureMap(feat);
  }
  for (int i=0; i < targetFields.length; i++) {
    totalTargetOP[i]=new ClassicCounter();
    parentFeatureMaps[i]=new FeatureMap(feat);
  }
  double logLike=0.0;
  for (int d=0, tsize=trainDocs.size(); d < tsize; d++) {
    if (!respectTypes && badDocs.contains(Integer.valueOf(d))) {
      if (verbose) {
        System.err.println("Skipping doc " + d + " because constrained expectations couldn't generate it");
      }
      continue;
    }
    Document doc=(Document)trainDocs.get(d);
    int numTimes=doc.size() + 2;
    double[][] thisP=new double[numStates][numStates];
    double[] thisFrom=new double[numStates];
    boolean zeroed=!forwardAlgorithm(doc,useScaling,respectTypes);
    if (printAllTrellises) {
      printTrellis("Forward for doc " + d,alpha,0,9,6);
      if (useScaling) {
        printStateVector("Scaling for doc " + d,scale);
      }
    }
    if (!zeroed) {
      backwardAlgorithm(doc,useScaling,respectTypes);
      if (printAllTrellises) {
        printTrellis("Backward for doc " + d,beta,numTimes - 10,numTimes - 1,6);
      }
      for (int t=0; t < numTimes - 1; t++) {
        TypedTaggedWord ttw=null;
        if (t < numTimes - 2) {
          ttw=(TypedTaggedWord)doc.get(t);
        }
        double sumAll=0.0;
        for (int i=0; i < numStates; i++) {
          double sumTerm=0.0;
          for (int j=0; j < numStates; j++) {
            double term;
            if (ttw == null) {
              if (states[j].emit == null) {
                term=alpha[i][t] * states[i].transition[j] * beta[j][t + 1];
              }
 else {
                term=0.0;
              }
            }
 else             if (ttw.type() != states[j].type || states[j].emit == null) {
              term=0.0;
            }
 else {
              term=alpha[i][t] * states[i].transition[j] * states[j].emit.get(ttw.word())* beta[j][t + 1];
            }
            if (useScaling) {
              term*=scale[t + 1];
            }
            thisP[i][j]+=term;
            sumTerm+=term;
            if (sanityCheck && Double.isNaN(term)) {
              System.err.println("term is nan");
              System.err.println("alpha[" + i + "]["+ t+ "]="+ alpha[i][t]);
              System.err.println("transition: " + states[i].transition[j]);
              if (states[j].emit == null) {
                System.err.println("YIKES!! state " + j + " has null emit map");
                System.exit(1);
              }
              System.err.println("emit (" + ttw.word() + "): "+ states[j].emit.get(ttw.word()));
              System.err.println("beta: " + beta[j][t + 1]);
            }
            if (false && term != 0.0) {
              System.err.println("Doc " + d + " time "+ t+ " trans "+ i+ "->"+ j+ " = "+ term);
            }
          }
          double tfTerm=alpha[i][t] * beta[i][t];
          thisFrom[i]+=tfTerm;
          if (sanityCheck && Math.abs(sumTerm - tfTerm) > TOLERANCE) {
            System.err.println("SumTerm is " + sumTerm + "; alpha beta is "+ tfTerm+ " for t="+ t+ ", state i="+ i);
            System.err.println("SumTerm is Sum_j thisP[i][j][t] " + "alphaBeta is P[i][t]");
            printStateVector("thisP(" + i + "--> .) = ",thisP[i]);
            System.err.println();
          }
          sumAll+=tfTerm;
          TypedTaggedWord ttwi=null;
          if (t > 0) {
            ttwi=(TypedTaggedWord)doc.get(t - 1);
          }
          if (i > State.STARTIDX && ttwi != null && !(states[i].emit instanceof ConstantEmitMap)) {
            String ttwiWord=ttwi.word();
            totalOP[i].incrementCount(ttwiWord,tfTerm);
            if (unseenMode == UNSEENMODE_HOLD_OUT_MASS && vocab.getCount(ttwiWord) == 1) {
              featureMaps[i].addToCount(ttwiWord,tfTerm);
              parentFeatureMaps[states[i].type].addToCount(ttwiWord,tfTerm);
            }
 else {
              totalSeenP[i]+=tfTerm;
              totalParentSeenP[states[i].type]+=tfTerm;
            }
            if (sanityCheck && (states[i].type < 0 || states[i].type >= totalTargetOP.length)) {
              System.err.println("Bad: states[i].type: " + states[i].type);
              System.err.println(" totalTargetOP:" + totalTargetOP.length);
            }
            totalTargetOP[states[i].type].incrementCount(ttwiWord,tfTerm);
            totalTargetOD[states[i].type]+=tfTerm;
          }
        }
        if (sanityCheck && useScaling) {
          if (Math.abs(sumAll - 1.0) > TOLERANCE) {
            System.err.println("expectations bung: for time " + t + " sum_i alpha(i)beta(i) = "+ sumAll);
          }
        }
      }
      double docLikelihood=lastDocumentLogLikelihood(useScaling);
      logLike+=docLikelihood;
      if (!useScaling) {
        for (int i=0; i < numStates; i++) {
          for (int j=0; j < numStates; j++) {
            thisP[i][j]/=docLikelihood;
          }
          thisFrom[i]/=docLikelihood;
        }
      }
      if (printAllTrellises) {
        printTrellis("E(thisP i-->j)",thisP,0,numStates - 1);
        printStateVector("thisFrom i",thisFrom);
      }
      for (int i=0; i < numStates; i++) {
        for (int j=0; j < numStates; j++) {
          totalP[i][j]+=thisP[i][j];
        }
        totalFrom[i]+=thisFrom[i];
      }
    }
 else {
      badDocs.add(Integer.valueOf(d));
      if (verbose) {
        System.err.println("HMM.expectations: warning: " + "couldn't generate document " + d + ".");
      }
      if (printAllTrellises) {
        for (int t=0; t < doc.size(); t++) {
          TypedTaggedWord ttw=(TypedTaggedWord)(doc.get(t));
          System.err.print(ttw.word() + ' ');
        }
        System.err.println();
      }
    }
  }
  if (badDocs.size() > 0 && verbose) {
    System.err.println("Parameters couldn't generate " + badDocs.size() + " documents.");
  }
  if (printAllTrellises) {
    System.err.println("Expectations for state changes");
    for (int i=0; i < totalP.length; i++) {
      printStateVector("E(" + i + "--> .)"+ i,totalP[i]);
    }
    printStateVector("E(state)",totalFrom);
  }
  return logLike;
}
