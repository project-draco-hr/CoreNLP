{
  boolean computeDataFreq=false;
  if (Data.processedDataFreq == null) {
    computeDataFreq=true;
    Data.processedDataFreq=new ClassicCounter<String>();
  }
  Counter<String> words=learnNewPhrasesPrivate(label,patternsForEachToken,patternsLearnedThisIter,allSelectedPatterns,constVars.getLabelDictionary().get(label),tokensMatchedPatterns,scoreForAllWordsThisIteration,terms,wordsPatExtracted,currentAllPatternWeights,patternsAndWords4Label,allPatternsAndWords4Label,identifier,ignoreWords,computeDataFreq);
  constVars.getLabelDictionary().get(label).addAll(words.keySet());
  if (computeDataFreq) {
    if (!phraseScorer.wordFreqNorm.equals(Normalization.NONE)) {
      Redwood.log(Redwood.DBG,"computing processed freq");
      for (      Entry<String,Double> fq : Data.rawFreq.entrySet()) {
        double in=fq.getValue();
        if (phraseScorer.wordFreqNorm.equals(Normalization.SQRT))         in=Math.sqrt(in);
 else         if (phraseScorer.wordFreqNorm.equals(Normalization.LOG))         in=1 + Math.log(in);
 else         throw new RuntimeException("can't understand the normalization");
        Data.processedDataFreq.setCount(fq.getKey(),in);
      }
    }
 else     Data.processedDataFreq=Data.rawFreq;
  }
  return words;
}
