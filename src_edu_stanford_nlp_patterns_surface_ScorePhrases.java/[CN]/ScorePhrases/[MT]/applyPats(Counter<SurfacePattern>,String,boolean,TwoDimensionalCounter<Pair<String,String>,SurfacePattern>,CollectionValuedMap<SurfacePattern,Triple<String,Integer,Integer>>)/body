{
  Counter<SurfacePattern> patternsLearnedThisIterConsistsOnlyGeneralized=new ClassicCounter<SurfacePattern>();
  Counter<SurfacePattern> patternsLearnedThisIterRest=new ClassicCounter<SurfacePattern>();
  Set<String> specialWords=constVars.invertedIndex.getSpecialWordsList();
  List<String> extremelySmallStopWordsList=Arrays.asList(".",",","in","on","of","a","the","an");
  for (  Entry<SurfacePattern,Double> en : patterns.entrySet()) {
    SurfacePattern p=en.getKey();
    String[] n=p.getOriginalNext();
    String[] pr=p.getOriginalPrev();
    boolean rest=false;
    if (n != null) {
      for (      String e : n) {
        if (!specialWords.contains(e)) {
          rest=true;
          break;
        }
      }
    }
    if (rest == false && pr != null) {
      for (      String e : pr) {
        if (!specialWords.contains(e) && !extremelySmallStopWordsList.contains(e)) {
          rest=true;
          break;
        }
      }
    }
    if (rest)     patternsLearnedThisIterRest.setCount(en.getKey(),en.getValue());
 else     patternsLearnedThisIterConsistsOnlyGeneralized.setCount(en.getKey(),en.getValue());
  }
  Map<String,Set<String>> sentidswithfilerest=constVars.invertedIndex.getFileSentIdsFromPats(patternsLearnedThisIterRest.keySet());
  if (constVars.batchProcessSents) {
    List<File> filesToLoad;
    if (patternsLearnedThisIterConsistsOnlyGeneralized.size() > 0)     filesToLoad=Data.sentsFiles;
 else {
      filesToLoad=new ArrayList<File>();
      for (      String fname : sentidswithfilerest.keySet()) {
        filesToLoad.add(new File(constVars.saveSentencesSerDir + "/" + fname));
      }
    }
    for (    File fname : filesToLoad) {
      Redwood.log(Redwood.DBG,"Applying patterns to sents from " + fname);
      Map<String,List<CoreLabel>> sents=IOUtils.readObjectFromFile(fname);
      if (sentidswithfilerest != null && !sentidswithfilerest.isEmpty()) {
        Set<String> sentIDs=sentidswithfilerest.get(fname.getName());
        if (sentIDs != null) {
          this.runParallelApplyPats(sents,sentIDs,label,patternsLearnedThisIterRest,wordsandLemmaPatExtracted,matchedTokensByPat);
        }
      }
      if (patternsLearnedThisIterConsistsOnlyGeneralized.size() > 0) {
        this.runParallelApplyPats(sents,sents.keySet(),label,patternsLearnedThisIterConsistsOnlyGeneralized,wordsandLemmaPatExtracted,matchedTokensByPat);
      }
      if (computeDataFreq)       Data.computeRawFreqIfNull(sents,constVars.numWordsCompound);
    }
  }
 else {
    if (sentidswithfilerest != null && !sentidswithfilerest.isEmpty()) {
      Set<String> sentids=sentidswithfilerest.get(CollectionUtils.toList(sentidswithfilerest.keySet()).get(0));
      if (sentids != null) {
        this.runParallelApplyPats(Data.sents,sentids,label,patternsLearnedThisIterRest,wordsandLemmaPatExtracted,matchedTokensByPat);
      }
    }
    if (patternsLearnedThisIterConsistsOnlyGeneralized.size() > 0) {
      this.runParallelApplyPats(Data.sents,Data.sents.keySet(),label,patternsLearnedThisIterConsistsOnlyGeneralized,wordsandLemmaPatExtracted,matchedTokensByPat);
    }
    Data.computeRawFreqIfNull(Data.sents,constVars.numWordsCompound);
  }
}
