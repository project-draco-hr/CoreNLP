{
  if (args.length < minArgs) {
    System.out.println(usage.toString());
    System.exit(-1);
  }
  Language lang=Language.English;
  TreebankLangParserParams tlpp=new EnglishTreebankParserParams();
  boolean VERBOSE=false;
  boolean collapseUnaries=false;
  boolean outputFreq=false;
  int sampleSize=-1;
  File treeFile=null;
  for (int i=0; i < args.length; i++) {
    if (args[i].startsWith("-")) {
      if (args[i].equals("-l")) {
        lang=Language.valueOf(args[++i].trim());
        tlpp=Languages.getLanguageParams(lang);
      }
 else       if (args[i].equals("-v")) {
        VERBOSE=true;
      }
 else       if (args[i].equals("-u")) {
        collapseUnaries=true;
      }
 else       if (args[i].equals("-s")) {
        sampleSize=Integer.parseInt(args[++i].trim());
      }
 else       if (args[i].equals("-f")) {
        outputFreq=true;
      }
 else {
        System.out.println(usage.toString());
        System.exit(-1);
      }
    }
 else {
      treeFile=new File(args[i]);
      break;
    }
  }
  final PrintWriter pwOut=tlpp.pw();
  final Treebank tb=tlpp.diskTreebank();
  tb.loadPath(treeFile);
  if (VERBOSE)   pwOut.println(tb.textualSummary());
  pwOut.println("Reading trees:");
  final Map<String,Counter<String>> ngramLabelMap=new HashMap<String,Counter<String>>(20000000);
  final Map<String,Set<Integer>> ngramIndex=new HashMap<String,Set<Integer>>();
  final TreebankLanguagePack tlp=tlpp.treebankLanguagePack();
  int numTrees=0;
  for (  Tree t : tb) {
    if (tlp.isStartSymbol(t.value()))     t=t.firstChild();
    if (collapseUnaries)     collapseUnaries(t);
    final Set<Constituent> constituents=makeConstituents(t);
    final ArrayList<Label> sentence=t.yield();
    final Set<ConcreteNgram> sentNgrams=extractNgrams(sentence);
    for (    final Constituent c : constituents) {
      LabeledConstituent lc=(LabeledConstituent)c;
      ConcreteNgram constituentNgram=new ConcreteNgram();
      constituentNgram.str=Sentence.extractNgram(sentence,lc.start(),lc.end() + 1);
      constituentNgram.start=lc.start();
      constituentNgram.order=lc.end() - lc.start() + 1;
      if (!ngramIndex.containsKey(constituentNgram.str))       ngramIndex.put(constituentNgram.str,new HashSet<Integer>());
      ngramIndex.get(constituentNgram.str).add(numTrees + 1);
      sentNgrams.remove(constituentNgram);
      if (!ngramLabelMap.containsKey(constituentNgram.str))       ngramLabelMap.put(constituentNgram.str,new ClassicCounter<String>());
      ngramLabelMap.get(constituentNgram.str).incrementCount(lc.label().value());
    }
    for (    ConcreteNgram ngram : sentNgrams) {
      if (ngram.order == 1)       continue;
      if (!ngramLabelMap.containsKey(ngram.str))       ngramLabelMap.put(ngram.str,new ClassicCounter<String>());
      ngramLabelMap.get(ngram.str).incrementCount("NIL");
      if (!ngramIndex.containsKey(ngram.str))       ngramIndex.put(ngram.str,new HashSet<Integer>());
      ngramIndex.get(ngram.str).add(numTrees + 1);
    }
    numTrees++;
    if ((numTrees % 200) == 0) {
      System.out.print(".");
    }
    if ((numTrees % 4000) == 0) {
      System.out.println();
      System.out.println("Map: " + ngramLabelMap.keySet().size());
    }
  }
  final List<Triple<Double,String,Set<String>>> nucleiSet=new ArrayList<Triple<Double,String,Set<String>>>(40000);
  double entropies=0.0;
  for (  String ngram : ngramLabelMap.keySet()) {
    Counter<String> cnt=ngramLabelMap.get(ngram);
    if (cnt.keySet().size() > 1) {
      double freq=cnt.totalCount();
      double entropy=Counters.entropy(cnt);
      entropies+=entropy;
      nucleiSet.add(new Triple<Double,String,Set<String>>((outputFreq) ? freq : entropy,ngram,cnt.keySet()));
    }
  }
  pwOut.println("\n\n=======================================================================");
  pwOut.println("Language:             " + lang.toString());
  pwOut.println("Input file:           " + treeFile.getPath());
  pwOut.println("Num. trees:           " + numTrees);
  pwOut.println("Variation nuclei:     " + nucleiSet.size());
  pwOut.println("Macro Avg. entropy:   " + entropies / (double)nucleiSet.size());
  pwOut.println("=======================================================================");
  try {
    PrintStream ps=new PrintFile(treeFile.getName() + ".ngram.index");
    if (sampleSize > 0) {
      final Random rand=new Random();
      Set<Integer> sampledIndices=new HashSet<Integer>();
      int numSamples=0;
      while (numSamples < sampleSize) {
        int sampleIdx=rand.nextInt(nucleiSet.size());
        if (!sampledIndices.contains(sampleIdx)) {
          Triple<Double,String,Set<String>> nucleus=nucleiSet.get(sampleIdx);
          pwOut.printf("%f\t%s\t%s\n",nucleus.first(),nucleus.third().toString(),nucleus.second());
          ps.printf("%s %s\n",nucleus.second(),nucleus.third().toString());
          Set<Integer> docIds=ngramIndex.get(nucleus.second());
          for (          int idx : docIds)           ps.printf(" %d\n",idx);
          ps.println();
          sampledIndices.add(sampleIdx);
          numSamples++;
        }
      }
      pwOut.printf("\n\nGenerated %d samples and wrote index\n",numSamples);
    }
 else {
      for (      Triple<Double,String,Set<String>> nucleus : nucleiSet) {
        pwOut.printf("%f\t%s\t%s%n",nucleus.first(),nucleus.third().toString(),nucleus.second());
        StringBuilder sb=new StringBuilder();
        Set<Integer> treeIds=ngramIndex.get(nucleus.second());
        for (        int idx : treeIds)         sb.append(idx).append(",");
        ps.printf("%s\t%d\t%s\t%s%n",nucleus.second(),(int)((double)nucleus.first()),nucleus.third().toString(),sb.toString());
      }
      pwOut.println();
    }
    ps.close();
  }
 catch (  IOException e) {
    e.printStackTrace();
  }
}
