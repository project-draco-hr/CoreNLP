{
  model.vectorToParams(theta);
  final ModelDerivatives derivatives=new ModelDerivatives(model);
  List<Tree> forwardPropTrees=Generics.newArrayList();
  for (  Tree tree : trainingBatch) {
    Tree trainingTree=tree.deepCopy();
    forwardPropagateTree(trainingTree);
    forwardPropTrees.add(trainingTree);
  }
  double error=0.0;
  for (  Tree tree : forwardPropTrees) {
    backpropDerivativesAndError(tree,derivatives.binaryTD,derivatives.binaryCD,derivatives.binaryTensorTD,derivatives.unaryCD,derivatives.wordVectorD);
    error+=sumError(tree);
  }
  double scale=(1.0 / trainingBatch.size());
  value=error * scale;
  value+=scaleAndRegularize(derivatives.binaryTD,model.binaryTransform,scale,model.op.trainOptions.regTransformMatrix,false);
  value+=scaleAndRegularize(derivatives.binaryCD,model.binaryClassification,scale,model.op.trainOptions.regClassification,true);
  value+=scaleAndRegularizeTensor(derivatives.binaryTensorTD,model.binaryTensors,scale,model.op.trainOptions.regTransformTensor);
  value+=scaleAndRegularize(derivatives.unaryCD,model.unaryClassification,scale,model.op.trainOptions.regClassification,false,true);
  value+=scaleAndRegularize(derivatives.wordVectorD,model.wordVectors,scale,model.op.trainOptions.regWordVector,true,false);
  derivative=NeuralUtils.paramsToVector(theta.length,derivatives.binaryTD.valueIterator(),derivatives.binaryCD.valueIterator(),SimpleTensor.iteratorSimpleMatrix(derivatives.binaryTensorTD.valueIterator()),derivatives.unaryCD.values().iterator(),derivatives.wordVectorD.values().iterator());
}
