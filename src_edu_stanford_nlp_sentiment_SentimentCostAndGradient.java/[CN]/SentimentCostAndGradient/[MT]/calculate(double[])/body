{
  model.vectorToParams(theta);
  double localValue=0.0;
  double[] localDerivative=new double[theta.length];
  TwoDimensionalMap<String,String,SimpleMatrix> binaryTD=TwoDimensionalMap.treeMap();
  TwoDimensionalMap<String,String,SimpleTensor> binaryTensorTD=TwoDimensionalMap.treeMap();
  TwoDimensionalMap<String,String,SimpleMatrix> binaryCD=TwoDimensionalMap.treeMap();
  Map<String,SimpleMatrix> unaryCD=Generics.newTreeMap();
  Map<String,SimpleMatrix> wordVectorD=Generics.newTreeMap();
  for (  TwoDimensionalMap.Entry<String,String,SimpleMatrix> entry : model.binaryTransform) {
    int numRows=entry.getValue().numRows();
    int numCols=entry.getValue().numCols();
    binaryTD.put(entry.getFirstKey(),entry.getSecondKey(),new SimpleMatrix(numRows,numCols));
  }
  if (!model.op.combineClassification) {
    for (    TwoDimensionalMap.Entry<String,String,SimpleMatrix> entry : model.binaryClassification) {
      int numRows=entry.getValue().numRows();
      int numCols=entry.getValue().numCols();
      binaryCD.put(entry.getFirstKey(),entry.getSecondKey(),new SimpleMatrix(numRows,numCols));
    }
  }
  if (model.op.useTensors) {
    for (    TwoDimensionalMap.Entry<String,String,SimpleTensor> entry : model.binaryTensors) {
      int numRows=entry.getValue().numRows();
      int numCols=entry.getValue().numCols();
      int numSlices=entry.getValue().numSlices();
      binaryTensorTD.put(entry.getFirstKey(),entry.getSecondKey(),new SimpleTensor(numRows,numCols,numSlices));
    }
  }
  for (  Map.Entry<String,SimpleMatrix> entry : model.unaryClassification.entrySet()) {
    int numRows=entry.getValue().numRows();
    int numCols=entry.getValue().numCols();
    unaryCD.put(entry.getKey(),new SimpleMatrix(numRows,numCols));
  }
  for (  Map.Entry<String,SimpleMatrix> entry : model.wordVectors.entrySet()) {
    int numRows=entry.getValue().numRows();
    int numCols=entry.getValue().numCols();
    wordVectorD.put(entry.getKey(),new SimpleMatrix(numRows,numCols));
  }
  List<Tree> forwardPropTrees=Generics.newArrayList();
  for (  Tree tree : trainingBatch) {
    Tree trainingTree=tree.deepCopy();
    forwardPropagateTree(trainingTree);
    forwardPropTrees.add(trainingTree);
  }
  double error=0.0;
  for (  Tree tree : forwardPropTrees) {
    backpropDerivativesAndError(tree,binaryTD,binaryCD,binaryTensorTD,unaryCD,wordVectorD);
    error+=sumError(tree);
  }
  double scale=(1.0 / trainingBatch.size());
  value=error * scale;
  value+=scaleAndRegularize(binaryTD,model.binaryTransform,scale,model.op.trainOptions.regTransformMatrix);
  value+=scaleAndRegularize(binaryCD,model.binaryClassification,scale,model.op.trainOptions.regClassification);
  value+=scaleAndRegularizeTensor(binaryTensorTD,model.binaryTensors,scale,model.op.trainOptions.regTransformTensor);
  value+=scaleAndRegularize(unaryCD,model.unaryClassification,scale,model.op.trainOptions.regClassification);
  value+=scaleAndRegularize(wordVectorD,model.wordVectors,scale,model.op.trainOptions.regWordVector);
  derivative=NeuralUtils.paramsToVector(theta.length,binaryTD.valueIterator(),binaryCD.valueIterator(),SimpleTensor.iteratorSimpleMatrix(binaryTensorTD.valueIterator()),unaryCD.values().iterator(),wordVectorD.values().iterator());
}
