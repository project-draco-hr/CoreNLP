{
  model.vectorToParams(theta);
  final ModelDerivatives derivatives;
  if (model.op.trainOptions.nThreads == 1) {
    derivatives=scoreDerivatives(trainingBatch);
  }
 else {
    MulticoreWrapper<List<Tree>,ModelDerivatives> wrapper=new MulticoreWrapper<>(model.op.trainOptions.nThreads,new ScoringProcessor());
    for (    List<Tree> chunk : CollectionUtils.partitionIntoFolds(trainingBatch,wrapper.nThreads())) {
      wrapper.put(chunk);
    }
    wrapper.join();
    derivatives=new ModelDerivatives(model);
    while (wrapper.peek()) {
      ModelDerivatives batchDerivatives=wrapper.poll();
      derivatives.add(batchDerivatives);
    }
  }
  double scale=(1.0 / trainingBatch.size());
  value=derivatives.error * scale;
  value+=scaleAndRegularize(derivatives.binaryTD,model.binaryTransform,scale,model.op.trainOptions.regTransformMatrix,false);
  value+=scaleAndRegularize(derivatives.binaryCD,model.binaryClassification,scale,model.op.trainOptions.regClassification,true);
  value+=scaleAndRegularizeTensor(derivatives.binaryTensorTD,model.binaryTensors,scale,model.op.trainOptions.regTransformTensor);
  value+=scaleAndRegularize(derivatives.unaryCD,model.unaryClassification,scale,model.op.trainOptions.regClassification,false,true);
  value+=scaleAndRegularize(derivatives.wordVectorD,model.wordVectors,scale,model.op.trainOptions.regWordVector,true,false);
  derivative=NeuralUtils.paramsToVector(theta.length,derivatives.binaryTD.valueIterator(),derivatives.binaryCD.valueIterator(),SimpleTensor.iteratorSimpleMatrix(derivatives.binaryTensorTD.valueIterator()),derivatives.unaryCD.values().iterator(),derivatives.wordVectorD.values().iterator());
}
