{
  edu.stanford.nlp.pipeline.CoreMapProtos.Document result=new edu.stanford.nlp.pipeline.CoreMapProtos.Document(this);
  int from_bitField0_=bitField0_;
  int to_bitField0_=0;
  if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
    to_bitField0_|=0x00000001;
  }
  result.text_=text_;
  if (tokensBuilder_ == null) {
    if (((bitField0_ & 0x00000002) == 0x00000002)) {
      tokens_=java.util.Collections.unmodifiableList(tokens_);
      bitField0_=(bitField0_ & ~0x00000002);
    }
    result.tokens_=tokens_;
  }
 else {
    result.tokens_=tokensBuilder_.build();
  }
  if (sentencesBuilder_ == null) {
    if (((bitField0_ & 0x00000004) == 0x00000004)) {
      sentences_=java.util.Collections.unmodifiableList(sentences_);
      bitField0_=(bitField0_ & ~0x00000004);
    }
    result.sentences_=sentences_;
  }
 else {
    result.sentences_=sentencesBuilder_.build();
  }
  if (corefChainsBuilder_ == null) {
    if (((bitField0_ & 0x00000008) == 0x00000008)) {
      corefChains_=java.util.Collections.unmodifiableList(corefChains_);
      bitField0_=(bitField0_ & ~0x00000008);
    }
    result.corefChains_=corefChains_;
  }
 else {
    result.corefChains_=corefChainsBuilder_.build();
  }
  if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
    to_bitField0_|=0x00000002;
  }
  result.docID_=docID_;
  result.bitField0_=to_bitField0_;
  onBuilt();
  return result;
}
