{
  phraseScoresRaw.clear();
  learnedScores.clear();
  if (Data.domainNGramsFile != null)   Data.loadDomainNGrams();
  Data.computeRawFreqIfNull(constVars.numWordsCompound);
  Counter<String> scores=new ClassicCounter<String>();
  RVFDataset<String,ScorePhraseMeasures> dataset=choosedatums(label,forLearningPatterns,sents,constVars.answerClass.get(label),label,constVars.getOtherSemanticClasses(),constVars.ignoreWordswithClassesDuringSelection.get(label),constVars.perSelectRand,constVars.perSelectNeg,wordsPatExtracted,allSelectedPatterns);
  edu.stanford.nlp.classify.Classifier classifier;
  if (scoreClassifierType.equals(ClassifierType.LR)) {
    LogisticClassifierFactory<String,ScorePhraseMeasures> logfactory=new LogisticClassifierFactory<String,ScorePhraseMeasures>();
    LogPrior lprior=new LogPrior();
    lprior.setSigma(constVars.LRSigma);
    classifier=logfactory.trainClassifier(dataset,lprior,false);
    LogisticClassifier logcl=((LogisticClassifier)classifier);
    String l=(String)logcl.getLabelForInternalPositiveClass();
    Counter<String> weights=logcl.weightsAsGenericCounter();
    if (l.equals(Boolean.FALSE.toString())) {
      Counters.multiplyInPlace(weights,-1);
    }
    List<Pair<String,Double>> wtd=Counters.toDescendingMagnitudeSortedListWithCounts(weights);
    Redwood.log(ConstantsAndVariables.minimaldebug,"The weights are " + StringUtils.join(wtd.subList(0,Math.min(wtd.size(),200)),"\n"));
  }
 else   throw new RuntimeException("cannot identify classifier " + scoreClassifierType);
  BufferedWriter w=new BufferedWriter(new FileWriter("tempscorestrainer.txt"));
  System.out.println("size of learned scores is " + phraseScoresRaw.size());
  for (  String s : phraseScoresRaw.firstKeySet()) {
    w.write(s + "\t" + phraseScoresRaw.getCounter(s)+ "\n");
  }
  w.close();
  return classifier;
}
